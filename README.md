# Interpretability of Deep Learning

[深度学习的可解释性研究（一）—— 让模型具备说人话的能力](https://zhuanlan.zhihu.com/p/37223341)

[深度学习的可解释性研究（二）——不如打开箱子看一看](https://zhuanlan.zhihu.com/p/38151985)
隐层分析法

[深度学习的可解释性研究（三）——是谁在撩动琴弦](https://zhuanlan.zhihu.com/p/38568075)
敏感性分析方法
deepxplore: https://github.com/peikexin9/deepxplore
tensorfuzz: https://github.com/brain-research/tensorfuzz

[Visual Interpretability for Deep Learning: a Survey](https://arxiv.org/pdf/1802.00614.pdf)

[“信息瓶颈”理论揭示深度学习本质](http://www.sohu.com/a/193777221_473283)

[打开人工智能的黑盒子](https://zhuanlan.zhihu.com/p/58099941)
局部线性可解释性(LIME)
反卷积(Deconvolution)
Saliency Map
类激活地图(Class Activation Map)
Mask的方法

A Survey of Methods for Explaining Black Box Models: 什么是可解释性、基于解释的分类、解决模型解释问题、解决结果解释问题

## CNN Visualization 

## NLP Visualization

